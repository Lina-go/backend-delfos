{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Evaluation Analysis**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1. Load Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available result files (4):\n",
            "  - 20251216_051940_results.json\n",
            "  - 20251216_045535_results.json\n",
            "  - 20251215_204640_results.json\n",
            "  - 20251215_200331_results.json\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "RESULTS_DIR = Path(\"../results\")\n",
        "DECIMAL_TOLERANCE = 0.01\n",
        "RESULT_FILE = RESULTS_DIR / \"20251216_051940_results.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: 20251216_051940_results.json\n",
            "\n",
            "Metadata:\n",
            "  Timestamp: 2025-12-16T05:28:36.522529\n",
            "  Total queries: 5\n",
            "  Dataset: queries.csv\n"
          ]
        }
      ],
      "source": [
        "if not RESULT_FILE or not RESULT_FILE.exists():\n",
        "    raise FileNotFoundError(f\"No result files found in {RESULTS_DIR}\")\n",
        "\n",
        "print(f\"Loading: {RESULT_FILE.name}\")\n",
        "\n",
        "with open(RESULT_FILE, encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "metadata = data[\"metadata\"]\n",
        "results = data[\"results\"]\n",
        "\n",
        "print(f\"\\nMetadata:\")\n",
        "print(f\"  Timestamp: {metadata['timestamp']}\")\n",
        "print(f\"  Total queries: {metadata['total_queries']}\")\n",
        "print(f\"  Dataset: {metadata['dataset']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 5 query results\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>gold_archetype</th>\n",
              "      <th>gold_sql</th>\n",
              "      <th>gold_difficulty</th>\n",
              "      <th>gold_tables</th>\n",
              "      <th>gold_results</th>\n",
              "      <th>predicted_archetype</th>\n",
              "      <th>predicted_sql</th>\n",
              "      <th>predicted_results</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>¿Cuál es el saldo total de todas las cuentas a...</td>\n",
              "      <td>A</td>\n",
              "      <td>SELECT SUM(currentBalance) AS saldo_total FROM...</td>\n",
              "      <td>easy</td>\n",
              "      <td>[dbo.Accounts]</td>\n",
              "      <td>[{'saldo_total': 19192159.62}]</td>\n",
              "      <td>A</td>\n",
              "      <td>SELECT SUM(currentBalance) AS saldo_total FROM...</td>\n",
              "      <td>[{'saldo_total': 19192159.62}]</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68</td>\n",
              "      <td>¿Cuál es la tendencia de apertura de cuentas d...</td>\n",
              "      <td>B</td>\n",
              "      <td>SELECT YEAR(createdAt) AS anio, COUNT(*) AS cu...</td>\n",
              "      <td>easy</td>\n",
              "      <td>[dbo.Accounts]</td>\n",
              "      <td>[{'anio': 2020, 'cuentas_ahorro': 5}, {'anio':...</td>\n",
              "      <td>B</td>\n",
              "      <td>SELECT YEAR(createdAt) AS Año, COUNT(*) AS Can...</td>\n",
              "      <td>[{'Año': 2020, 'CantidadCuentasAbiertas': 5}, ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>112</td>\n",
              "      <td>¿Qué porcentaje de clientes son premium vs reg...</td>\n",
              "      <td>C</td>\n",
              "      <td>SELECT customerType, COUNT(*) * 100.0 / (SELEC...</td>\n",
              "      <td>easy</td>\n",
              "      <td>[dbo.Customers]</td>\n",
              "      <td>[{'customerType': 'premium', 'porcentaje': 15....</td>\n",
              "      <td>C</td>\n",
              "      <td>SELECT \\n&nbsp;&nbsp;&nbsp;&nbsp;customerType,\\n&nbsp;&nbsp;&nbsp;&nbsp;COUNT(*) AS ca...</td>\n",
              "      <td>[{'customerType': 'premium', 'cantidad_cliente...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>159</td>\n",
              "      <td>¿Qué porcentaje del total de empleados son Tel...</td>\n",
              "      <td>D</td>\n",
              "      <td>SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FRO...</td>\n",
              "      <td>easy</td>\n",
              "      <td>[dbo.Employees]</td>\n",
              "      <td>[{'participacion_pct': 16.0}]</td>\n",
              "      <td>C</td>\n",
              "      <td>SELECT \\n&nbsp;&nbsp;&nbsp;&nbsp;CAST(COUNT(CASE WHEN position = '...</td>\n",
              "      <td>[{'porcentaje_tellers': 16.0, 'total_tellers':...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>207</td>\n",
              "      <td>¿Cómo contribuye cada estado de préstamo al mo...</td>\n",
              "      <td>E</td>\n",
              "      <td>SELECT status, SUM(loanAmount) AS monto_contri...</td>\n",
              "      <td>easy</td>\n",
              "      <td>[dbo.Loans]</td>\n",
              "      <td>[{'status': 'active', 'monto_contribucion': 18...</td>\n",
              "      <td>E</td>\n",
              "      <td>SELECT status AS Estado, COUNT(*) AS CantidadP...</td>\n",
              "      <td>[{'Estado': 'active', 'CantidadPrestamos': 592...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                           question gold_archetype  \\\n",
              "0    0  ¿Cuál es el saldo total de todas las cuentas a...              A   \n",
              "1   68  ¿Cuál es la tendencia de apertura de cuentas d...              B   \n",
              "2  112  ¿Qué porcentaje de clientes son premium vs reg...              C   \n",
              "3  159  ¿Qué porcentaje del total de empleados son Tel...              D   \n",
              "4  207  ¿Cómo contribuye cada estado de préstamo al mo...              E   \n",
              "\n",
              "                                            gold_sql gold_difficulty  \\\n",
              "0  SELECT SUM(currentBalance) AS saldo_total FROM...            easy   \n",
              "1  SELECT YEAR(createdAt) AS anio, COUNT(*) AS cu...            easy   \n",
              "2  SELECT customerType, COUNT(*) * 100.0 / (SELEC...            easy   \n",
              "3  SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FRO...            easy   \n",
              "4  SELECT status, SUM(loanAmount) AS monto_contri...            easy   \n",
              "\n",
              "       gold_tables                                       gold_results  \\\n",
              "0   [dbo.Accounts]                     [{'saldo_total': 19192159.62}]   \n",
              "1   [dbo.Accounts]  [{'anio': 2020, 'cuentas_ahorro': 5}, {'anio':...   \n",
              "2  [dbo.Customers]  [{'customerType': 'premium', 'porcentaje': 15....   \n",
              "3  [dbo.Employees]                      [{'participacion_pct': 16.0}]   \n",
              "4      [dbo.Loans]  [{'status': 'active', 'monto_contribucion': 18...   \n",
              "\n",
              "  predicted_archetype                                      predicted_sql  \\\n",
              "0                   A  SELECT SUM(currentBalance) AS saldo_total FROM...   \n",
              "1                   B  SELECT YEAR(createdAt) AS Año, COUNT(*) AS Can...   \n",
              "2                   C  SELECT \\n    customerType,\\n    COUNT(*) AS ca...   \n",
              "3                   C  SELECT \\n    CAST(COUNT(CASE WHEN position = '...   \n",
              "4                   E  SELECT status AS Estado, COUNT(*) AS CantidadP...   \n",
              "\n",
              "                                   predicted_results error  \n",
              "0                     [{'saldo_total': 19192159.62}]  None  \n",
              "1  [{'Año': 2020, 'CantidadCuentasAbiertas': 5}, ...  None  \n",
              "2  [{'customerType': 'premium', 'cantidad_cliente...  None  \n",
              "3  [{'porcentaje_tellers': 16.0, 'total_tellers':...  None  \n",
              "4  [{'Estado': 'active', 'CantidadPrestamos': 592...  None  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(f\"\\nLoaded {len(df)} query results\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2. Calculate Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_results(gold_results, predicted_results, tolerance=DECIMAL_TOLERANCE):\n",
        "    \"\"\"\n",
        "    Compare gold and predicted results.\n",
        "    \n",
        "    Rules:\n",
        "    - Predicted can have EXTRA columns (agent returned more info) - OK\n",
        "    - Predicted must have ALL gold columns with matching values\n",
        "    - Numeric values compared within tolerance\n",
        "    - Row order does not matter\n",
        "    \"\"\"\n",
        "    if gold_results is None and predicted_results is None:\n",
        "        return True\n",
        "    if gold_results is None or predicted_results is None:\n",
        "        return False\n",
        "    if not gold_results and not predicted_results:\n",
        "        return True\n",
        "    if not gold_results or not predicted_results:\n",
        "        return False\n",
        "    \n",
        "    def normalize_value(v):\n",
        "        if isinstance(v, float):\n",
        "            return round(v, 2)\n",
        "        return v\n",
        "    \n",
        "    def normalize_row(row):\n",
        "        if isinstance(row, dict):\n",
        "            return {k.lower(): normalize_value(v) for k, v in row.items()}\n",
        "        return row\n",
        "    \n",
        "    def values_match(gold_val, pred_val):\n",
        "        if gold_val is None and pred_val is None:\n",
        "            return True\n",
        "        if gold_val is None or pred_val is None:\n",
        "            return False\n",
        "        if isinstance(gold_val, (int, float)) and isinstance(pred_val, (int, float)):\n",
        "            return abs(gold_val - pred_val) <= tolerance\n",
        "        return gold_val == pred_val\n",
        "    \n",
        "    def rows_match(gold_row, pred_row):\n",
        "        gold_keys = set(gold_row.keys())\n",
        "        pred_keys = set(pred_row.keys())\n",
        "        \n",
        "        if not gold_keys.issubset(pred_keys):\n",
        "            gold_vals = sorted([v for v in gold_row.values() if v is not None], \n",
        "                             key=lambda x: (type(x).__name__, str(x)))\n",
        "            pred_vals_available = list(pred_row.values())\n",
        "            for gold_val in gold_vals:\n",
        "                found = False\n",
        "                for i, pred_val in enumerate(pred_vals_available):\n",
        "                    if values_match(normalize_value(gold_val), normalize_value(pred_val)):\n",
        "                        pred_vals_available.pop(i)\n",
        "                        found = True\n",
        "                        break\n",
        "                if not found:\n",
        "                    return False\n",
        "            return True\n",
        "        \n",
        "        for key in gold_keys:\n",
        "            gold_val = normalize_value(gold_row[key])\n",
        "            pred_val = normalize_value(pred_row.get(key))\n",
        "            if not values_match(gold_val, pred_val):\n",
        "                return False\n",
        "        return True\n",
        "    \n",
        "    gold_normalized = [normalize_row(r) for r in gold_results]\n",
        "    pred_normalized = [normalize_row(r) for r in predicted_results]\n",
        "    \n",
        "    if len(gold_normalized) != len(pred_normalized):\n",
        "        return False\n",
        "    \n",
        "    if len(gold_normalized) == 1:\n",
        "        return rows_match(gold_normalized[0], pred_normalized[0])\n",
        "    \n",
        "    pred_matched = [False] * len(pred_normalized)\n",
        "    for gold_row in gold_normalized:\n",
        "        found_match = False\n",
        "        for i, pred_row in enumerate(pred_normalized):\n",
        "            if not pred_matched[i] and rows_match(gold_row, pred_row):\n",
        "                pred_matched[i] = True\n",
        "                found_match = True\n",
        "                break\n",
        "        if not found_match:\n",
        "            return False\n",
        "    \n",
        "    return all(pred_matched)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics columns added:\n",
            "['archetype_match', 'sql_generated', 'sql_executed', 'has_error', 'execution_match', 'gold_empty', 'pred_empty', 'row_count_match', 'gold_row_count', 'pred_row_count']\n"
          ]
        }
      ],
      "source": [
        "def calculate_query_metrics(row):\n",
        "    metrics = {}\n",
        "    \n",
        "    gold_arch = row.get(\"gold_archetype\")\n",
        "    pred_arch = row.get(\"predicted_archetype\")\n",
        "    metrics[\"archetype_match\"] = (\n",
        "        gold_arch is not None and \n",
        "        pred_arch is not None and \n",
        "        str(gold_arch).upper() == str(pred_arch).upper()\n",
        "    )\n",
        "    \n",
        "    pred_sql = row.get(\"predicted_sql\")\n",
        "    metrics[\"sql_generated\"] = pred_sql is not None and len(str(pred_sql).strip()) > 0\n",
        "    \n",
        "    error = row.get(\"error\")\n",
        "    pred_results = row.get(\"predicted_results\")\n",
        "    metrics[\"sql_executed\"] = error is None and pred_results is not None\n",
        "    \n",
        "    metrics[\"has_error\"] = error is not None\n",
        "    \n",
        "    gold_results = row.get(\"gold_results\")\n",
        "    metrics[\"execution_match\"] = compare_results(gold_results, pred_results)\n",
        "    \n",
        "    metrics[\"gold_empty\"] = not gold_results or len(gold_results) == 0\n",
        "    metrics[\"pred_empty\"] = not pred_results or len(pred_results) == 0\n",
        "    \n",
        "    gold_count = len(gold_results) if gold_results else 0\n",
        "    pred_count = len(pred_results) if pred_results else 0\n",
        "    metrics[\"row_count_match\"] = gold_count == pred_count\n",
        "    metrics[\"gold_row_count\"] = gold_count\n",
        "    metrics[\"pred_row_count\"] = pred_count\n",
        "    \n",
        "    return pd.Series(metrics)\n",
        "\n",
        "metrics_df = df.apply(calculate_query_metrics, axis=1)\n",
        "df = pd.concat([df, metrics_df], axis=1)\n",
        "\n",
        "print(\"Metrics columns added:\")\n",
        "print(metrics_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3. Summary Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "   DELFOS NL2SQL EVALUATION REPORT\n",
            "============================================================\n",
            "\n",
            "Dataset: queries.csv\n",
            "Timestamp: 2025-12-16T05:28:36.522529\n",
            "Total Queries: 5\n",
            "\n",
            "------------------------------------------------------------\n",
            "   CORE METRICS\n",
            "------------------------------------------------------------\n",
            "\n",
            "Execution Accuracy (EX):        100.0%  (5/5)  <- MAIN\n",
            "Archetype Accuracy:              80.0%  (4/5)\n",
            "SQL Generation Rate:            100.0%  (5/5)\n",
            "SQL Execution Rate:             100.0%  (5/5)\n",
            "Error Rate:                       0.0%  (0/5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_summary_report(df):\n",
        "    total = len(df)\n",
        "    \n",
        "    archetype_acc = df[\"archetype_match\"].sum() / total * 100\n",
        "    sql_gen_rate = df[\"sql_generated\"].sum() / total * 100\n",
        "    sql_exec_rate = df[\"sql_executed\"].sum() / total * 100\n",
        "    execution_acc = df[\"execution_match\"].sum() / total * 100\n",
        "    error_rate = df[\"has_error\"].sum() / total * 100\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"   DELFOS NL2SQL EVALUATION REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nDataset: {metadata.get('dataset', 'N/A')}\")\n",
        "    print(f\"Timestamp: {metadata.get('timestamp', 'N/A')}\")\n",
        "    print(f\"Total Queries: {total}\")\n",
        "    print()\n",
        "    print(\"-\" * 60)\n",
        "    print(\"   CORE METRICS\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"\\nExecution Accuracy (EX):       {execution_acc:6.1f}%  ({df['execution_match'].sum()}/{total})\")\n",
        "    print(f\"Archetype Accuracy:            {archetype_acc:6.1f}%  ({df['archetype_match'].sum()}/{total})\")\n",
        "    print(f\"SQL Generation Rate:           {sql_gen_rate:6.1f}%  ({df['sql_generated'].sum()}/{total})\")\n",
        "    print(f\"SQL Execution Rate:            {sql_exec_rate:6.1f}%  ({df['sql_executed'].sum()}/{total})\")\n",
        "    print(f\"Error Rate:                    {error_rate:6.1f}%  ({df['has_error'].sum()}/{total})\")\n",
        "    print()\n",
        "    \n",
        "    return {\n",
        "        \"total_queries\": total,\n",
        "        \"execution_accuracy\": execution_acc,\n",
        "        \"archetype_accuracy\": archetype_acc,\n",
        "        \"sql_generation_rate\": sql_gen_rate,\n",
        "        \"sql_execution_rate\": sql_exec_rate,\n",
        "        \"error_rate\": error_rate\n",
        "    }\n",
        "\n",
        "summary = print_summary_report(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **4. Breakdown by Archetype**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "   BY ARCHETYPE\n",
            "------------------------------------------------------------\n",
            "\n",
            "Archetype    EX Accuracy        Arch Accuracy   Queries   \n",
            "-------------------------------------------------------\n",
            "A            100.0% (1/1)       100.0%          1         \n",
            "B            100.0% (1/1)       100.0%          1         \n",
            "C            100.0% (1/1)       100.0%          1         \n",
            "D            100.0% (1/1)       0.0%            1         \n",
            "E            100.0% (1/1)       100.0%          1         \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_archetype_breakdown(df):\n",
        "    print(\"-\" * 60)\n",
        "    print(\"   BY ARCHETYPE\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    stats = df.groupby(\"gold_archetype\").agg({\n",
        "        \"execution_match\": [\"sum\", \"count\"],\n",
        "        \"archetype_match\": \"sum\"\n",
        "    }).round(2)\n",
        "    \n",
        "    stats.columns = [\"ex_correct\", \"total\", \"arch_correct\"]\n",
        "    stats[\"ex_accuracy\"] = (stats[\"ex_correct\"] / stats[\"total\"] * 100).round(1)\n",
        "    stats[\"arch_accuracy\"] = (stats[\"arch_correct\"] / stats[\"total\"] * 100).round(1)\n",
        "    \n",
        "    print(f\"\\n{'Archetype':<12} {'EX Accuracy':<18} {'Arch Accuracy':<15} {'Queries':<10}\")\n",
        "    print(\"-\" * 55)\n",
        "    \n",
        "    for arch in sorted(stats.index):\n",
        "        row = stats.loc[arch]\n",
        "        total = int(row[\"total\"])\n",
        "        ex_str = f\"{row['ex_accuracy']:.1f}% ({int(row['ex_correct'])}/{total})\"\n",
        "        arch_str = f\"{row['arch_accuracy']:.1f}%\"\n",
        "        print(f\"{arch:<12} {ex_str:<18} {arch_str:<15} {total:<10}\")\n",
        "    \n",
        "    print()\n",
        "    return stats\n",
        "\n",
        "archetype_stats = print_archetype_breakdown(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **5. Breakdown by Difficulty**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "   BY DIFFICULTY\n",
            "------------------------------------------------------------\n",
            "\n",
            "Difficulty   EX Accuracy        Queries   \n",
            "----------------------------------------\n",
            "easy         100.0% (5/5)       5         \n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_difficulty_breakdown(df):\n",
        "    print(\"-\" * 60)\n",
        "    print(\"   BY DIFFICULTY\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    stats = df.groupby(\"gold_difficulty\").agg({\n",
        "        \"execution_match\": [\"sum\", \"count\"]\n",
        "    }).round(2)\n",
        "    \n",
        "    stats.columns = [\"ex_correct\", \"total\"]\n",
        "    stats[\"ex_accuracy\"] = (stats[\"ex_correct\"] / stats[\"total\"] * 100).round(1)\n",
        "    \n",
        "    difficulty_order = [\"easy\", \"medium\", \"hard\"]\n",
        "    stats = stats.reindex([d for d in difficulty_order if d in stats.index])\n",
        "    \n",
        "    print(f\"\\n{'Difficulty':<12} {'EX Accuracy':<18} {'Queries':<10}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    for diff in stats.index:\n",
        "        row = stats.loc[diff]\n",
        "        total = int(row[\"total\"])\n",
        "        ex_str = f\"{row['ex_accuracy']:.1f}% ({int(row['ex_correct'])}/{total})\"\n",
        "        print(f\"{diff:<12} {ex_str:<18} {total:<10}\")\n",
        "    \n",
        "    print()\n",
        "    return stats\n",
        "\n",
        "difficulty_stats = print_difficulty_breakdown(df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
=======
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation Analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available result files (4):\n",
      "  - 20251216_051940_results.json\n",
      "  - 20251216_045535_results.json\n",
      "  - 20251215_204640_results.json\n",
      "  - 20251215_200331_results.json\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "DECIMAL_TOLERANCE = 0.01\n",
    "RESULT_FILE = RESULTS_DIR / \"20251216_051940_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: 20251216_051940_results.json\n",
      "\n",
      "Metadata:\n",
      "  Timestamp: 2025-12-16T05:28:36.522529\n",
      "  Total queries: 5\n",
      "  Dataset: queries.csv\n"
     ]
    }
   ],
   "source": [
    "if not RESULT_FILE or not RESULT_FILE.exists():\n",
    "    raise FileNotFoundError(f\"No result files found in {RESULTS_DIR}\")\n",
    "\n",
    "print(f\"Loading: {RESULT_FILE.name}\")\n",
    "\n",
    "with open(RESULT_FILE, encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "metadata = data[\"metadata\"]\n",
    "results = data[\"results\"]\n",
    "\n",
    "print(\"\\nMetadata:\")\n",
    "print(f\"  Timestamp: {metadata['timestamp']}\")\n",
    "print(f\"  Total queries: {metadata['total_queries']}\")\n",
    "print(f\"  Dataset: {metadata['dataset']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 5 query results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>gold_archetype</th>\n",
       "      <th>gold_sql</th>\n",
       "      <th>gold_difficulty</th>\n",
       "      <th>gold_tables</th>\n",
       "      <th>gold_results</th>\n",
       "      <th>predicted_archetype</th>\n",
       "      <th>predicted_sql</th>\n",
       "      <th>predicted_results</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>¿Cuál es el saldo total de todas las cuentas a...</td>\n",
       "      <td>A</td>\n",
       "      <td>SELECT SUM(currentBalance) AS saldo_total FROM...</td>\n",
       "      <td>easy</td>\n",
       "      <td>[dbo.Accounts]</td>\n",
       "      <td>[{'saldo_total': 19192159.62}]</td>\n",
       "      <td>A</td>\n",
       "      <td>SELECT SUM(currentBalance) AS saldo_total FROM...</td>\n",
       "      <td>[{'saldo_total': 19192159.62}]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>¿Cuál es la tendencia de apertura de cuentas d...</td>\n",
       "      <td>B</td>\n",
       "      <td>SELECT YEAR(createdAt) AS anio, COUNT(*) AS cu...</td>\n",
       "      <td>easy</td>\n",
       "      <td>[dbo.Accounts]</td>\n",
       "      <td>[{'anio': 2020, 'cuentas_ahorro': 5}, {'anio':...</td>\n",
       "      <td>B</td>\n",
       "      <td>SELECT YEAR(createdAt) AS Año, COUNT(*) AS Can...</td>\n",
       "      <td>[{'Año': 2020, 'CantidadCuentasAbiertas': 5}, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>¿Qué porcentaje de clientes son premium vs reg...</td>\n",
       "      <td>C</td>\n",
       "      <td>SELECT customerType, COUNT(*) * 100.0 / (SELEC...</td>\n",
       "      <td>easy</td>\n",
       "      <td>[dbo.Customers]</td>\n",
       "      <td>[{'customerType': 'premium', 'porcentaje': 15....</td>\n",
       "      <td>C</td>\n",
       "      <td>SELECT \\n&nbsp;&nbsp;&nbsp;&nbsp;customerType,\\n&nbsp;&nbsp;&nbsp;&nbsp;COUNT(*) AS ca...</td>\n",
       "      <td>[{'customerType': 'premium', 'cantidad_cliente...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159</td>\n",
       "      <td>¿Qué porcentaje del total de empleados son Tel...</td>\n",
       "      <td>D</td>\n",
       "      <td>SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FRO...</td>\n",
       "      <td>easy</td>\n",
       "      <td>[dbo.Employees]</td>\n",
       "      <td>[{'participacion_pct': 16.0}]</td>\n",
       "      <td>C</td>\n",
       "      <td>SELECT \\n&nbsp;&nbsp;&nbsp;&nbsp;CAST(COUNT(CASE WHEN position = '...</td>\n",
       "      <td>[{'porcentaje_tellers': 16.0, 'total_tellers':...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>¿Cómo contribuye cada estado de préstamo al mo...</td>\n",
       "      <td>E</td>\n",
       "      <td>SELECT status, SUM(loanAmount) AS monto_contri...</td>\n",
       "      <td>easy</td>\n",
       "      <td>[dbo.Loans]</td>\n",
       "      <td>[{'status': 'active', 'monto_contribucion': 18...</td>\n",
       "      <td>E</td>\n",
       "      <td>SELECT status AS Estado, COUNT(*) AS CantidadP...</td>\n",
       "      <td>[{'Estado': 'active', 'CantidadPrestamos': 592...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question gold_archetype  \\\n",
       "0    0  ¿Cuál es el saldo total de todas las cuentas a...              A   \n",
       "1   68  ¿Cuál es la tendencia de apertura de cuentas d...              B   \n",
       "2  112  ¿Qué porcentaje de clientes son premium vs reg...              C   \n",
       "3  159  ¿Qué porcentaje del total de empleados son Tel...              D   \n",
       "4  207  ¿Cómo contribuye cada estado de préstamo al mo...              E   \n",
       "\n",
       "                                            gold_sql gold_difficulty  \\\n",
       "0  SELECT SUM(currentBalance) AS saldo_total FROM...            easy   \n",
       "1  SELECT YEAR(createdAt) AS anio, COUNT(*) AS cu...            easy   \n",
       "2  SELECT customerType, COUNT(*) * 100.0 / (SELEC...            easy   \n",
       "3  SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FRO...            easy   \n",
       "4  SELECT status, SUM(loanAmount) AS monto_contri...            easy   \n",
       "\n",
       "       gold_tables                                       gold_results  \\\n",
       "0   [dbo.Accounts]                     [{'saldo_total': 19192159.62}]   \n",
       "1   [dbo.Accounts]  [{'anio': 2020, 'cuentas_ahorro': 5}, {'anio':...   \n",
       "2  [dbo.Customers]  [{'customerType': 'premium', 'porcentaje': 15....   \n",
       "3  [dbo.Employees]                      [{'participacion_pct': 16.0}]   \n",
       "4      [dbo.Loans]  [{'status': 'active', 'monto_contribucion': 18...   \n",
       "\n",
       "  predicted_archetype                                      predicted_sql  \\\n",
       "0                   A  SELECT SUM(currentBalance) AS saldo_total FROM...   \n",
       "1                   B  SELECT YEAR(createdAt) AS Año, COUNT(*) AS Can...   \n",
       "2                   C  SELECT \\n    customerType,\\n    COUNT(*) AS ca...   \n",
       "3                   C  SELECT \\n    CAST(COUNT(CASE WHEN position = '...   \n",
       "4                   E  SELECT status AS Estado, COUNT(*) AS CantidadP...   \n",
       "\n",
       "                                   predicted_results error  \n",
       "0                     [{'saldo_total': 19192159.62}]  None  \n",
       "1  [{'Año': 2020, 'CantidadCuentasAbiertas': 5}, ...  None  \n",
       "2  [{'customerType': 'premium', 'cantidad_cliente...  None  \n",
       "3  [{'porcentaje_tellers': 16.0, 'total_tellers':...  None  \n",
       "4  [{'Estado': 'active', 'CantidadPrestamos': 592...  None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(f\"\\nLoaded {len(df)} query results\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Calculate Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(gold_results, predicted_results, tolerance=DECIMAL_TOLERANCE):\n",
    "    \"\"\"\n",
    "    Compare gold and predicted results.\n",
    "\n",
    "    Rules:\n",
    "    - Predicted can have EXTRA columns (agent returned more info) - OK\n",
    "    - Predicted must have ALL gold columns with matching values\n",
    "    - Numeric values compared within tolerance\n",
    "    - Row order does not matter\n",
    "    \"\"\"\n",
    "    if gold_results is None and predicted_results is None:\n",
    "        return True\n",
    "    if gold_results is None or predicted_results is None:\n",
    "        return False\n",
    "    if not gold_results and not predicted_results:\n",
    "        return True\n",
    "    if not gold_results or not predicted_results:\n",
    "        return False\n",
    "\n",
    "    def normalize_value(v):\n",
    "        if isinstance(v, float):\n",
    "            return round(v, 2)\n",
    "        return v\n",
    "\n",
    "    def normalize_row(row):\n",
    "        if isinstance(row, dict):\n",
    "            return {k.lower(): normalize_value(v) for k, v in row.items()}\n",
    "        return row\n",
    "\n",
    "    def values_match(gold_val, pred_val):\n",
    "        if gold_val is None and pred_val is None:\n",
    "            return True\n",
    "        if gold_val is None or pred_val is None:\n",
    "            return False\n",
    "        if isinstance(gold_val, (int, float)) and isinstance(pred_val, (int, float)):\n",
    "            return abs(gold_val - pred_val) <= tolerance\n",
    "        return gold_val == pred_val\n",
    "\n",
    "    def rows_match(gold_row, pred_row):\n",
    "        gold_keys = set(gold_row.keys())\n",
    "        pred_keys = set(pred_row.keys())\n",
    "\n",
    "        if not gold_keys.issubset(pred_keys):\n",
    "            gold_vals = sorted(\n",
    "                [v for v in gold_row.values() if v is not None],\n",
    "                key=lambda x: (type(x).__name__, str(x)),\n",
    "            )\n",
    "            pred_vals_available = list(pred_row.values())\n",
    "            for gold_val in gold_vals:\n",
    "                found = False\n",
    "                for i, pred_val in enumerate(pred_vals_available):\n",
    "                    if values_match(normalize_value(gold_val), normalize_value(pred_val)):\n",
    "                        pred_vals_available.pop(i)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        for key in gold_keys:\n",
    "            gold_val = normalize_value(gold_row[key])\n",
    "            pred_val = normalize_value(pred_row.get(key))\n",
    "            if not values_match(gold_val, pred_val):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    gold_normalized = [normalize_row(r) for r in gold_results]\n",
    "    pred_normalized = [normalize_row(r) for r in predicted_results]\n",
    "\n",
    "    if len(gold_normalized) != len(pred_normalized):\n",
    "        return False\n",
    "\n",
    "    if len(gold_normalized) == 1:\n",
    "        return rows_match(gold_normalized[0], pred_normalized[0])\n",
    "\n",
    "    pred_matched = [False] * len(pred_normalized)\n",
    "    for gold_row in gold_normalized:\n",
    "        found_match = False\n",
    "        for i, pred_row in enumerate(pred_normalized):\n",
    "            if not pred_matched[i] and rows_match(gold_row, pred_row):\n",
    "                pred_matched[i] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            return False\n",
    "\n",
    "    return all(pred_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics columns added:\n",
      "['archetype_match', 'sql_generated', 'sql_executed', 'has_error', 'execution_match', 'gold_empty', 'pred_empty', 'row_count_match', 'gold_row_count', 'pred_row_count']\n"
     ]
    }
   ],
   "source": [
    "def calculate_query_metrics(row):\n",
    "    metrics = {}\n",
    "\n",
    "    gold_arch = row.get(\"gold_archetype\")\n",
    "    pred_arch = row.get(\"predicted_archetype\")\n",
    "    metrics[\"archetype_match\"] = (\n",
    "        gold_arch is not None\n",
    "        and pred_arch is not None\n",
    "        and str(gold_arch).upper() == str(pred_arch).upper()\n",
    "    )\n",
    "\n",
    "    pred_sql = row.get(\"predicted_sql\")\n",
    "    metrics[\"sql_generated\"] = pred_sql is not None and len(str(pred_sql).strip()) > 0\n",
    "\n",
    "    error = row.get(\"error\")\n",
    "    pred_results = row.get(\"predicted_results\")\n",
    "    metrics[\"sql_executed\"] = error is None and pred_results is not None\n",
    "\n",
    "    metrics[\"has_error\"] = error is not None\n",
    "\n",
    "    gold_results = row.get(\"gold_results\")\n",
    "    metrics[\"execution_match\"] = compare_results(gold_results, pred_results)\n",
    "\n",
    "    metrics[\"gold_empty\"] = not gold_results or len(gold_results) == 0\n",
    "    metrics[\"pred_empty\"] = not pred_results or len(pred_results) == 0\n",
    "\n",
    "    gold_count = len(gold_results) if gold_results else 0\n",
    "    pred_count = len(pred_results) if pred_results else 0\n",
    "    metrics[\"row_count_match\"] = gold_count == pred_count\n",
    "    metrics[\"gold_row_count\"] = gold_count\n",
    "    metrics[\"pred_row_count\"] = pred_count\n",
    "\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "\n",
    "metrics_df = df.apply(calculate_query_metrics, axis=1)\n",
    "df = pd.concat([df, metrics_df], axis=1)\n",
    "\n",
    "print(\"Metrics columns added:\")\n",
    "print(metrics_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Summary Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "   DELFOS NL2SQL EVALUATION REPORT\n",
      "============================================================\n",
      "\n",
      "Dataset: queries.csv\n",
      "Timestamp: 2025-12-16T05:28:36.522529\n",
      "Total Queries: 5\n",
      "\n",
      "------------------------------------------------------------\n",
      "   CORE METRICS\n",
      "------------------------------------------------------------\n",
      "\n",
      "Execution Accuracy (EX):        100.0%  (5/5)  <- MAIN\n",
      "Archetype Accuracy:              80.0%  (4/5)\n",
      "SQL Generation Rate:            100.0%  (5/5)\n",
      "SQL Execution Rate:             100.0%  (5/5)\n",
      "Error Rate:                       0.0%  (0/5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_summary_report(df):\n",
    "    total = len(df)\n",
    "\n",
    "    archetype_acc = df[\"archetype_match\"].sum() / total * 100\n",
    "    sql_gen_rate = df[\"sql_generated\"].sum() / total * 100\n",
    "    sql_exec_rate = df[\"sql_executed\"].sum() / total * 100\n",
    "    execution_acc = df[\"execution_match\"].sum() / total * 100\n",
    "    error_rate = df[\"has_error\"].sum() / total * 100\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"   DELFOS NL2SQL EVALUATION REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nDataset: {metadata.get('dataset', 'N/A')}\")\n",
    "    print(f\"Timestamp: {metadata.get('timestamp', 'N/A')}\")\n",
    "    print(f\"Total Queries: {total}\")\n",
    "    print()\n",
    "    print(\"-\" * 60)\n",
    "    print(\"   CORE METRICS\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\n",
    "        f\"\\nExecution Accuracy (EX):       {execution_acc:6.1f}%  ({df['execution_match'].sum()}/{total})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Archetype Accuracy:            {archetype_acc:6.1f}%  ({df['archetype_match'].sum()}/{total})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"SQL Generation Rate:           {sql_gen_rate:6.1f}%  ({df['sql_generated'].sum()}/{total})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"SQL Execution Rate:            {sql_exec_rate:6.1f}%  ({df['sql_executed'].sum()}/{total})\"\n",
    "    )\n",
    "    print(f\"Error Rate:                    {error_rate:6.1f}%  ({df['has_error'].sum()}/{total})\")\n",
    "    print()\n",
    "\n",
    "    return {\n",
    "        \"total_queries\": total,\n",
    "        \"execution_accuracy\": execution_acc,\n",
    "        \"archetype_accuracy\": archetype_acc,\n",
    "        \"sql_generation_rate\": sql_gen_rate,\n",
    "        \"sql_execution_rate\": sql_exec_rate,\n",
    "        \"error_rate\": error_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "summary = print_summary_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Breakdown by Archetype**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "   BY ARCHETYPE\n",
      "------------------------------------------------------------\n",
      "\n",
      "Archetype    EX Accuracy        Arch Accuracy   Queries   \n",
      "-------------------------------------------------------\n",
      "A            100.0% (1/1)       100.0%          1         \n",
      "B            100.0% (1/1)       100.0%          1         \n",
      "C            100.0% (1/1)       100.0%          1         \n",
      "D            100.0% (1/1)       0.0%            1         \n",
      "E            100.0% (1/1)       100.0%          1         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_archetype_breakdown(df):\n",
    "    print(\"-\" * 60)\n",
    "    print(\"   BY ARCHETYPE\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    stats = (\n",
    "        df.groupby(\"gold_archetype\")\n",
    "        .agg({\"execution_match\": [\"sum\", \"count\"], \"archetype_match\": \"sum\"})\n",
    "        .round(2)\n",
    "    )\n",
    "\n",
    "    stats.columns = [\"ex_correct\", \"total\", \"arch_correct\"]\n",
    "    stats[\"ex_accuracy\"] = (stats[\"ex_correct\"] / stats[\"total\"] * 100).round(1)\n",
    "    stats[\"arch_accuracy\"] = (stats[\"arch_correct\"] / stats[\"total\"] * 100).round(1)\n",
    "\n",
    "    print(f\"\\n{'Archetype':<12} {'EX Accuracy':<18} {'Arch Accuracy':<15} {'Queries':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for arch in sorted(stats.index):\n",
    "        row = stats.loc[arch]\n",
    "        total = int(row[\"total\"])\n",
    "        ex_str = f\"{row['ex_accuracy']:.1f}% ({int(row['ex_correct'])}/{total})\"\n",
    "        arch_str = f\"{row['arch_accuracy']:.1f}%\"\n",
    "        print(f\"{arch:<12} {ex_str:<18} {arch_str:<15} {total:<10}\")\n",
    "\n",
    "    print()\n",
    "    return stats\n",
    "\n",
    "\n",
    "archetype_stats = print_archetype_breakdown(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Breakdown by Difficulty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "   BY DIFFICULTY\n",
      "------------------------------------------------------------\n",
      "\n",
      "Difficulty   EX Accuracy        Queries   \n",
      "----------------------------------------\n",
      "easy         100.0% (5/5)       5         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_difficulty_breakdown(df):\n",
    "    print(\"-\" * 60)\n",
    "    print(\"   BY DIFFICULTY\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    stats = df.groupby(\"gold_difficulty\").agg({\"execution_match\": [\"sum\", \"count\"]}).round(2)\n",
    "\n",
    "    stats.columns = [\"ex_correct\", \"total\"]\n",
    "    stats[\"ex_accuracy\"] = (stats[\"ex_correct\"] / stats[\"total\"] * 100).round(1)\n",
    "\n",
    "    difficulty_order = [\"easy\", \"medium\", \"hard\"]\n",
    "    stats = stats.reindex([d for d in difficulty_order if d in stats.index])\n",
    "\n",
    "    print(f\"\\n{'Difficulty':<12} {'EX Accuracy':<18} {'Queries':<10}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for diff in stats.index:\n",
    "        row = stats.loc[diff]\n",
    "        total = int(row[\"total\"])\n",
    "        ex_str = f\"{row['ex_accuracy']:.1f}% ({int(row['ex_correct'])}/{total})\"\n",
    "        print(f\"{diff:<12} {ex_str:<18} {total:<10}\")\n",
    "\n",
    "    print()\n",
    "    return stats\n",
    "\n",
    "\n",
    "difficulty_stats = print_difficulty_breakdown(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
>>>>>>> d984b5989bc14dd90921e4148562a2126609854f
}
